# **부스트캠프 AI Tech 5기 07조 Final Project**


[CHOSEN](http://chosen.o-r.kr/)

<img width="800" alt="Untitled" src="./utils/img/overview.png">

<br/><br/>

# 👋 반갑습니다.

안녕하세요. 저희 `연어보다자연어` 팀은 2023년 6월 30일 ~ 7월 28일까지  **사용자의 입력에 따른 리뷰 기반 상품 추천 서비스** 를 진행했습니다. 쿠팡의 리뷰데이터를 수집하여 **AI 모델로 요약문을 생성**했습니다. 요약문을 query 로, 리뷰데이터를 context 로 사용하여 **retrieve 모델을 학습**시켰습니다. 이것을 토대로 사용자 입력에 맞는 상품을 추천해주는 리뷰 기반 AI 서비스를 개발했습니다.

<br/>

## 팀원 소개

| <img src="https://avatars.githubusercontent.com/u/81620001?v=4" width = 120> | <img src="https://avatars.githubusercontent.com/u/86578246?v=4" width=120> | <img src="https://avatars.githubusercontent.com/u/126573689?v=4" width=120> | <img src="https://avatars.githubusercontent.com/u/96599427?v=4" width=120> | <img src="https://avatars.githubusercontent.com/u/89494907?v=4" width=120> |
| --- | --- | --- | --- | --- |
| 권지은_T5018<br>[@lectura7942](https://github.com/lectura7942) | 김재연_T5051<br>[@JLake310](https://github.com/JLake310) | 박영준_T5087<br>[@hoooolllly](https://github.com/hoooolllly) | 정다혜_T5189<br>[@Da-Hye-JUNG](https://github.com/Da-Hye-JUNG) | 최윤진_T5218<br>[@yunjinchoidev](https://github.com/yunjinchoidev) |

<br/>


## 팀원 역할

- `권지은`: 데이터 필터링, 요약 모델 학습 데이터 제작, 요약 모델 학습 및 평가, 요약 API 제작
- `김재연`: Project Manager, DPR 학습 및 평가, 데이터 필터링, 프론트엔드 개발, 배포 및 유지/보수
- `박영준`: 데이터 필터링, 요약 모델 학습 데이터 제작
- `정다혜`: 요약 모델 학습 데이터 제작, 요약 모델 학습 및 평가
- `최윤진`: 데이터 수집, Airflow 스케줄링, DB API

<br/><br/>



# 🙌 프로젝트를 소개합니다.

## 문제 정의

세상엔 상품이 너무 많습니다.🤔  동시에 고객이 원하는 **조건**들은 점점 다양해지고 있습니다. 

많은 사람들이 자신에게 맞는 상품들을 고르기 위해 리뷰를 찾아보면서 제품들을 비교하며 고르고 있습니다. 이 과정에서 많은 시간이 허비되곤 합니다.

**저희 팀은 이런 불편함을 확인하고, 해결책으로써 리뷰 데이터에 주목했습니다.** 🔎 상품의 생생한 사용 후기와 느낌이 반영되어 있는 리뷰 데이터는 가치있는 데이터라고 할 수 있습니다. 

**딥러닝 모델을 통해 리뷰를 분석하고 사용자의 입력 조건에 맞는 상품을 추천해준다면 쇼핑에 불필요하게 낭비되는 시간을 절약**할 수 있을 거라는 생각을 하게 되었습니다. 특히 **상품들이 많고 리뷰 수, 사용자가 많은 ‘쿠팡’**이 저희 프로젝트에 가장 적합하다고 생각했습니다. 상품의 종류가 너무 많아 식품 데이터에 한정했습니다.

<br/>

## 우리는 이런 목표를 가지고 있어요.

✅ 사용자가 원하는 조건의 상품을 **한 눈에 모아볼 수 있도록** 하는 거예요.

✅ 사용자가 상품을 비교하고 선택하는 **시간을 줄일 수 있게** 도와주는 거예요.

✅ 피드백을 반영하여 추천 만족도를 **지속적으로** 높이도록 하는 거예요.

<img width="437" alt="Untitled" src="./utils/img/team_vision.png">

<br/><br/>

# ✈️ 먼저 서비스가 어떻게 돌아가는 지 보여드릴게요.

### 📌 한번 사용해보세요. 👉 [CHOSEN](http://chosen.o-r.kr/)

### 📌 바쁘신 분들을 위해 **데모 영상**을 첨부합니다.

- 검색한 상품이 DB 에 저장 된 경우
  
    [![Video Label](http://img.youtube.com/vi/dzFuc4AK6OQ/0.jpg)](https://youtu.be/dzFuc4AK6OQ)
    
    
- 검색한 상품이 저장되지 않아 실시간 크롤링 하는 경우
  
    [![Video Label](http://img.youtube.com/vi/nbzfXA41-X8/0.jpg)](https://youtu.be/nbzfXA41-X8)

    

### 📌 데이터베이스에 검색한 상품이 있는가 없는가에 따라 서비스 플로우가 달라집니다.

- 데이터베이스에 저장된 상품의 경우 10초 안에 결과를 볼 수 있습니다.
- 저장되지 않은 경우엔 실시간으로 데이터를 크롤링을 해서 1분 30초 ~2분 정도 시간이 소요됩니다.


<img width="1626" alt="Flow Chart long" src="./utils/img/Flow_Chart_long.png">

<br/><br/>

# ⏰ 저희는 이렇게 프로젝트를 진행했습니다.


이 글을 보는 여러분들께 저희 팀이 **어떤 문제를, 어떻게 해결해나갔는지** 말씀 드리고 싶습니다. 
**네 가지 관점**에서 저희의 이야기를 들려드리겠습니다. 

1️⃣ 어떻게 하면 **양질의 데이터**를 수집할 수 있을까?

2️⃣ 어떻게 하면 문서를 **키워드 중심으로 요약**할 수 있을까?

3️⃣ 어떻게 하면 비정형화된 **사용자의 피드백 데이터**를 다룰 수 있을까?

4️⃣ 어떻게 하면 서비스의 **결과를 보는 시간**을 줄일 수 있을까?




<br/><br/>


## 1️⃣ 어떻게 하면 **양질의 데이터**를 수집할 수 있을까?

AI 프로젝트의 첫 출발은 데이터 수집입니다. 이 과정에서 나온 데이터의 품질이 모델의 성능을 결정짓습니다. 

저희는 양질의 데이터를 수집하기 위해 노력하면서 여러 문제를 마주쳤습니다. **어떤 기준에 맞추어 데이터를 선별** 하는 게 좋을 지, 중요하지 않은 텍스트를 어떻게 **필터링하고 전처리할지** 고민해야 했습니다.

### 1-1 **상품 데이터 수집 기준 수립**

- **1 페이지에 나오는 임의의 제품들을 수집**
    
    쿠팡 검색을 하면 아래 화면처럼 36개 정도의 상품이 1페이지에 나옵니다. 처음엔 이 상품들을 **선별 없이** 모두 크롤링 했습니다. 검색 시 첫 페이지에 나오는 만큼 **보편적이고 다양한 제품들**이 나온다는 것을 알 수 있었습니다. 그만큼 사용자에게 여러 제품을 추천해준다는 점에서 이런 수집 방식은 장점을 가지고 있었지만, 동시에 **일반적인 선호도를 고려하지 못한다는 문제점**이 있었습니다. 
    


<img width="1626" alt="쿠팡에서 검색을 하면 약 36개의 상품이 나오고, top-10 상품에 대해선 상품 이미지 좌측 상단에 빨간 순위 태그가 붙습니다." src="./utils/img/coupang_top10.png">


쿠팡에서 검색을 하면 약 36개의 상품이 나오고, top-10 상품에 대해선 상품 이미지 좌측 상단에 빨간 순위 태그가 붙습니다. 

- **쿠팡에서 선정한 TOP10 상품 수집**
상품 이미지 좌측 상단을 보면 쿠팡에서 자체적으로 선정한 ‘**쿠팡 랭킹**’ 이라는 게 있습니다. **리뷰 수, 인기도, 판매량 등을 고려해서 쿠팡 자체적으로 10개의 상품에 태그를 이미 붙여준 것입니다**. 저희는 이런 데이터들이 일반적인 선호도를 반영한다고 생각했고 이 데이터만 수집하기로 결정했습니다. **리뷰 수가 이미 많은 top-10 상품들은 저희의 목표인 리뷰 데이터 기반 상품 서비스에 더 적합하다는 점도 고려했습니다.💡**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c8e30186-9a99-4e0c-a3d0-f178957eaf67/Untitled.png)

### 1-2 **리뷰 데이터 수집 기준 수립**

하나의 상품마다 20개의 리뷰를 수집했습니다. 리뷰 기반 추천 시스템이기 때문에 무엇보다 중요한 것은 리뷰 데이터의 품질이었습니다. 저희는 **리뷰의 길이, 유용성**을 기준으로 데이터의 수집 기준을 정했습니다. 

- **리뷰의 길이**
    
    리뷰 데이터가 **너무 짧거나** **너무 긴** 리뷰 데이터는 특성상 적합하지 않은 데이터라고 판단했습니다. 너무 짧은 텍스트는 표면적 감상에 치우쳐있고, 너무 긴 텍스트는 정보가 과도하게 퍼져있어서 사용하기엔 부적합하다고 판단 했기 때문입니다. ‘맛있어요’, ‘밥 맛이 땡겨요’ 와 같은 문장들이 대표적입니다.
    

- **유용성**
    
    쿠팡 자체적으로 ‘**도움이 돼요**’라는 지표를 가지고 있습니다. 이것이 한 번이라도 눌린 리뷰를 수집하여 **최소한의 유용성을 보장**하는 데이터를 수집했습니다.
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8f09ee1e-d144-46db-bb44-da0574c575f9/Untitled.png)
    

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d8948e79-e0dd-4518-8183-f218ea6ea629/Untitled.png)

결론적으로 저희가 최종적으로 수립한 **<리뷰 데이터 수집 기준>** 은 아래와 같습니다. 

1. **50자 이상, 500자 이내 리뷰만 수집하여 정제 및 활용에 적합하도록 함**
2. **‘도움이 돼요’ 평가를 한 번이라도 받은 데이터만 수집하여 최소한의 유용성을 보장** 

### 1-3 데이터 필터링

하지만 이렇게 수집한 리뷰 데이터들은 당연히 문제를 가지고 있었습니다. 🤔  대표적으로 리뷰 데이터의 문장들을 구체적으로 확인해보았을 때 **요리 방법, 인사말 등 요약에 필요하지 않은 문장**들이 존재했습니다. 아래 그림을 보면 확실히 알 수 있습니다. 저희는 요약의 품질 향상 및 시간 단축을 위해 **데이터 필터링 전략**에 대해 고민을 하게 되었습니다. 

![조리법 관련된 정보는 요약 정보에 필요하지 않습니다. ](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/954e79b7-1681-4c3f-9c7b-44ff5d98f8a6/Untitled.png)

조리법 관련된 정보는 요약 정보에 필요하지 않습니다. 

저희는 크게 두 가지 방식에서 접근했습니다. 

첫번째는 **클러스터링 기반 필터링**이고, 두 번째는 **규칙 기반 필터링**입니다. 

- **클러스터링 기반 필터링**
    
    **Kmeans 클러스터링**을 통해 조리법 관련 문장들을 제거하기 위한 시도를 했습니다. ‘맛’, ‘식감’, ‘조리’ 와 같은 **클러스터**를 만들어서 제거하는 방법이었습니다. 아래 그림 처럼 ‘조리’ 를 통해 클러스터링을 하면 관련된 문장들이 클러스터를 형성하는 것을 알 수 있습니다. **하지만 제거 해야하는 문장의 절반도 필터링하지 못 했습니다. 😂**
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3dc84c31-97e1-4b88-bb6d-d3d18dbd5408/Untitled.png)
    

- **규칙 기반 필터링**
    
    그래서 저희는 조리법, 배송 등의 관련된 **키워드를 직접 추출하여 불필요한 문장을 제거**해주었습니다. 
    
    단순한 방법이었지만 효과적이었습니다. 🤖
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e8ff0c58-afab-4729-add2-7c48b29d53ab/Untitled.png)
    

### 1-4 데이터 전처리

리뷰 데이터는 비정형 데이터이기 때문에 반드시 정제가 필요합니다. 아래 기준에 맞추어서 리뷰 데이터를 전처리 해주었습니다. hanspell 라이브러리를 이용해 맞춤법 검사도 해주었습니다. 

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/89187fb0-98d4-40f5-99e4-c6bce17aab2f/Untitled.png)

### 1-5 중복 상품 제거

**같은 상품이지만 중량 혹은 개수의 차이로 인해 쿠팡 top-10 랭킹에 여러 상품으로 표시되는 경우**도 있었습니다. 쿠팡에서 부여한 **고유 상품 번호**를 이용해서 중복된 데이터가 수집되는 것을 방지했습니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5aae064f-befd-4017-8112-31d10799bacc/Untitled.png)

저희는 위 과정을 거쳐 총 **506**개의 검색어에 대한 **4983**개의 상품 데이터, **77732**개의 리뷰 데이터를 수집했습니다.











# ☝️ Wrap Up


## 프로젝트 타임라인

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e0d116e2-f488-41b8-8197-808778d4397f/Untitled.png)

## 기술 스택

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7ea00a33-012d-4d6b-ae8d-53105e530aa1/Untitled.png)

## 프로젝트 플로우 차트

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3904ae61-8f80-4fc5-89bc-5123867f4ef7/Untitled.png)

## 서비스 아키텍처

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9b7636e4-a5fd-420a-af3f-bec482d0aa01/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/187bdd88-cc44-435e-a3c1-b07b1fd40ff9/Untitled.png)

## ERD

아래 ERD 대로 MySQL 테이블을 만들고 수집한 데이터를 저장해줬습니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/20ca4fbd-2762-4536-b605-5fef674a6c53/Untitled.png)

## 실제 데이터

아래와 같이 구성되어 있답니다. 

📌**상품 데이터**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/649e4323-a134-4a2a-b326-2910b6ea9a10/Untitled.png)

📌 **리뷰 데이터**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a138819f-dc2d-4266-a2e5-e3af50f02554/Untitled.png)

## 자체 평가 의견

### 프로젝트 달성도 및 완성도

- 실시간으로 크롤링하여 결과를 보여주는 부분까지 구현하고 배포하여, 프로젝트 초기에 수립한 목표는 모두 달성했다고 생각한다.
- 외부 데이터셋을 사용하지 않았기 때문에 프로젝트 그 자체로 완전함을 갖추었다고 생각한다.

### 프로젝트를 진행하면서 배운 점 혹은 성장한 점

- 짧은 기간 동안 타이트하게 일정을 조율하는 경험을 할 수 있었다.
- 서비스를 개발하고 알파테스트를 진행하여 피드백을 받았다. 이러한 피드백을 서비스에 반영하고 개선하며 사용자의 입장에서 한 번 더 생각해볼 수 있었다.
- 데이터 수집부터 배포까지 End2End로 AI 서비스를 만들어내면서, 실제 개발 과정에 대한 이해를 기를 수 있었다.
- 해결하고자 하는 문제에 맞는 평가지표를 선택하는 경험을 할 수 있었다.

### 프로젝트를 진행하면서 아쉬웠던 점

- 짧은 기간 동안 프로젝트의 배포까지 완수해야 하다보니, 모델링에 온전히 집중하지 못한 점이 아쉬웠다.
- OpenAI API로 제작한 데이터에 대한 검수가 부족한 것 같아서 아쉬웠다.
- 할루시네이션과 생성 결과 길이에 대한 평가 지표가 부족한 것 같아서 아쉬웠다.
- 피드백 데이터가 생각보다 안 모여서 제대로 활용할 수 없던 점이 아쉬웠다.

### 추후 개발하고 싶은 부분

- ColBERT로 retrieve를 시도해보고 싶다.
- API의 동기 요청을 통해 백그라운드에서 데이터를 수집하여 사용자의 대기 시간을 더 줄여보고 싶다.
- 크롤링 시간을 단축 시키고 싶다.

<br/><br/>

# 🙂 감사합니다.

지금까지 `연어보다자연어` 팀의 여정을 읽어주셔서 감사합니다.

<br/><br/>
해당 프로젝트는 네이버 커넥트재단의 부스트캠프 AI tech 5기에서 진행했습니다.
